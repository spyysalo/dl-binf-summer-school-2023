{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYkSLcRRsOt2xRo1LPx9aF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spyysalo/dl-binf-summer-school-2023/blob/main/galactica_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation with GALACTICA\n",
        "\n",
        "This notebook demonstrates text generation with a small GALACTICA model (https://galactica.org/) on Colab."
      ],
      "metadata": {
        "id": "upiVhm3M7i7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll install the required Python packages. The [transformers](https://huggingface.co/docs/transformers/index) package is used to load the model and run generation, and the [accelerate](https://huggingface.co/docs/accelerate/index) package supports running large models efficiently on multiple devices."
      ],
      "metadata": {
        "id": "-ImKmG7j70Z1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8jS-wINx56E5"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll import the `AutoTokenizer` and `AutoModelForCausalLM` classes. These support loading tokenizers and models from the [Hugging Face Hub](https://huggingface.co/models)."
      ],
      "metadata": {
        "id": "_Eo4L8Fg78HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "MTaE1wV5D8BD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a causal language model and its tokenizer. You can substitute any other causal model model name here (e.g. other GALACTICA models), but note that Colab may have issues running very large models."
      ],
      "metadata": {
        "id": "dALzr3qOIVlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = 'facebook/galactica-1.3b'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map='auto')"
      ],
      "metadata": {
        "id": "rVU1q0ch6dFY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll define a simple function to perform generation for a given text prompt using broadly reasonable parameters. For details on text generation using transformers, see e.g. [this tutorial](https://huggingface.co/blog/how-to-generate)."
      ],
      "metadata": {
        "id": "Q7_KDhT58c5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, temperature=0.7, max_new_tokens=100):\n",
        "    input_ids = tokenizer(prompt, return_tensors='pt').input_ids\n",
        "    input_ids.to(model.device)\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        do_sample=True,\n",
        "        temperature=temperature,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        no_repeat_ngram_size=2,\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "UfQwsdTQBNXg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run generation with a few example prompts.\n",
        "\n",
        "(Note that re-running these generation examples will produce different outputs as `model.generate` is invoked with the `do_sample=True` parameter.)"
      ],
      "metadata": {
        "id": "GJXzCH0UCBg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate('p53 is an extensively studied protein that is known to interact with'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVadcgJ57gBJ",
        "outputId": "800402c3-a820-4663-a2bd-9fd1fdd200df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p53 is an extensively studied protein that is known to interact with proteins that mediate DNA repair, cell cycle regulation, and apoptosis ( Functional interactions between p50(nrb) and p73: regulation of apoptosis, transcriptional activation, DNA binding, oligomerization, nuclear localization, subcellular localization and growth suppressor activity., Vousden).\n",
            "\n",
            "p70 S6 kinase 1 [p-p85α/α-subunit of PI3K] is a serine-threonine kinase that plays an important role in the regulation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate('The most significant risk factors for cancer include'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z6DKCoYAjfF",
        "outputId": "469dfb48-ee2d-40a3-a522-65e0dd0b7a31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most significant risk factors for cancer include smoking, alcohol consumption, and physical inactivity. Therefore, efforts to reduce the incidence of cancer are essential. In this study, we analyzed the association between the intake of green tea and the risk of lung cancer among 27,414 male workers in the Korean Working Environment Cohort study. Cox proportional hazards regression analysis was used to calculate hazard ratios (HRs) and 95% confidence intervals [CIs]. During follow-up, 331 cases of incident\n"
          ]
        }
      ]
    }
  ]
}